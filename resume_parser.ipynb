{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "f = open(\"./extracted_texts/a2353f5b-13bf-47a0-8994-5a025fb1b6dc.txt\",\n",
    "         'r')\n",
    "\n",
    "for x in f:\n",
    "    text+=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining spacy language model\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for token in doc:\n",
    "#     print(token, end=\"|\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Name(doc):\n",
    "    name = ''\n",
    "    for entity in doc.ents:\n",
    "        if entity.label_ == 'PERSON':\n",
    "            name = entity.text\n",
    "            break\n",
    "    return name.split('\\n')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quater'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_Name(doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email(doc):\n",
    "    \n",
    "    pattern = [{\"TEXT\": {\"REGEX\": \"[a-zA-Z0-9-_.]+@[a-zA-Z0-9-_.]+\"}}]\n",
    "\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    matcher.add(\"Email\",[pattern])\n",
    "\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end]\n",
    "        return span.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aism6486@gmail.com'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_email(doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phoneNumber(doc):\n",
    "    pattern = [{\"TEXT\": {\"REGEX\": \"[+0-9]{10,14}\"}}]\n",
    "    matcher = Matcher(nlp.vocab, validate=True)\n",
    "    matcher.add(\"PhoneNumber\", [pattern])\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end]\n",
    "        return span.text\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'+8801755304840'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_phoneNumber(doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SSC']\n"
     ]
    }
   ],
   "source": [
    "ayo = []\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "EDUCATION = [\n",
    "            'BE', 'B.E.', 'B.E', 'BS', 'B.S', 'ME', 'M.E',\n",
    "            'M.E.', 'MS', 'M.S', 'BTECH', 'MTECH',\n",
    "            'SSC', 'HSC', 'CBSE', 'ICSE'\n",
    "            ]\n",
    "        \n",
    "for token in doc:\n",
    "    token = re.sub(r'[?|$|.|!|,]', r'', token.text)\n",
    "    if token.upper() in EDUCATION:\n",
    "        ayo.append(token)\n",
    "    \n",
    "print(ayo)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu = {}\n",
    "ayo = []\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "EDUCATION = [\n",
    "            'BE', 'B.E.', 'B.E', 'BS', 'B.S', 'ME', 'M.E',\n",
    "            'M.E.', 'MS', 'M.S', 'BTECH', 'MTECH',\n",
    "            'SSC', 'HSC', 'CBSE', 'ICSE'\n",
    "            ]\n",
    "        \n",
    "for index, text in enumerate(doc.text):\n",
    "    for tex in text.split():\n",
    "        tex = re.sub(r'[?|$|.|!|,]', r'', tex)\n",
    "        if tex.upper() in EDUCATION and tex not in STOPWORDS:\n",
    "            edu[tex] = text + doc.text[index+1]\n",
    "            ayo.append(tex)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a1b3e2a2-b25b-4ead-aee3-fbaede8341ae.txt'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "extracted_texts_dir = '/home/epsilondelta/Work/ocr-project/extracted_texts/'\n",
    "os.listdir(extracted_texts_dir)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jabirnahian009@gmail.com\n",
      "Jabir Al Nahian\n",
      "+8801870761283\n",
      "*********\n",
      "aism6486@gmail.com\n",
      "Quater\n",
      "+8801755304840\n",
      "*********\n",
      "umnoon.ali@northsouth.edu\n",
      "Umnoon Binta Ali\n",
      "+8801627097553\n",
      "*********\n",
      "md.mohosin.sayam10@gmail.com\n",
      "MD Mohosin Sayam\n",
      "+8801841777516\n",
      "*********\n",
      "shagoto1710@cseku.ac.bd\n",
      "Shagoto Rahman\n",
      "+8801793157472\n",
      "*********\n",
      "saif.ndub@gmail.com\n",
      "Md Saif Hossain\n",
      "+8801566024660\n",
      "*********\n",
      "imsobhani171134@bscse.uiu.ac.bd\n",
      "Mahbub E Sobhani Himel\n",
      "01521333309\n",
      "*********\n",
      "mahmudsourav@gmail.com\n",
      "Md Subhul Mahmud Bokhary\n",
      "01913956096\n",
      "*********\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(extracted_texts_dir):\n",
    "    text = ''\n",
    "    f = open(os.path.join(extracted_texts_dir,file),'r')\n",
    "    for x in f:\n",
    "        text += x\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    print(get_email(doc))\n",
    "    print(get_Name(doc))\n",
    "    print(get_phoneNumber(doc))\n",
    "    print(\"*********\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('ocr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9df43e8394a06c2bd225e8c3cc0348707dbec1aac68919c3eb2d8230de0dd306"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
